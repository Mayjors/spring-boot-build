server.port=6666

# --- kafka ---
spring.kafka.bootstrap-servers=localhost:9092

# ======= provider =======
spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 制定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

# ====== consumer =======
# 制定默认消费者 group id
spring.kafka.consumer.group-id=test-consumer-group

spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
# --- kafka --- end -
# ==================

# 主数据源，默认的
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
  spring.datasource.url=jdbc:mysql://127.0.0.1:3306/db
  spring.datasource.username=root
  spring.datasource.password=123456
  # 初始化大小，最小，最大
 spring.datasource.initialSize=5
  spring.datasource.minIdle=5
  spring.datasource.maxActive=20
  # 配置获取连接等待超时的时间
spring.datasource.maxWait=60000\
  # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
  spring.datasource.timeBetweenEvictionRunsMillis=60000
  # 配置一个连接在池中最小生存的时间，单位是毫秒
spring.datasource.minEvictableIdleTimeMillis=300000
  spring.datasource.validationQuery=SELECT 1 FROM DUAL
  spring.datasource.testWhileIdle=true
  spring.datasource.testOnBorrow=false
  spring.datasource.testOnReturn=false
  # 打开PSCache，并且指定每个连接上PSCache的大小
  spring.datasource.poolPreparedStatements=true
  spring.datasource.maxPoolPreparedStatementPerConnectionSize=20 
  # 从数据源spring.slave.type=com.alibaba.druid.pool.DruidDataSource
spring.slave.driver-class-name=com.mysql.jdbc.Driver
  spring.slave.url=jdbc:mysql://127.0.0.1:3308/db
  spring.slave.username=root
  spring.slave.password=123456
  spring.slave.initialSize=5
  spring.slave.minIdle=5
  spring.slave.maxActive=20
  # 配置获取连接等待超时的时间spring.slave.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.slave.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.slave.minEvictableIdleTimeMillis=300000spring.slave.validationQuery=SELECT 1 FROM DUALspring.slave.testWhileIdle=truespring.slave.testOnBorrow=falsespring.slave.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.slave.poolPreparedStatements=truespring.slave.maxPoolPreparedStatementPerConnectionSize=20  spring.read2.type=com.alibaba.druid.pool.DruidDataSourcespring.read2.driver-class-name=com.mysql.jdbc.Driverspring.read2.url=jdbc:mysql://127.0.0.1:3309/dbspring.read2.username=rootspring.read2.password=123456spring.read2.initialSize=5spring.read2.minIdle=5spring.read2.maxActive=20# 配置获取连接等待超时的时间spring.read2.maxWait=60000# 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒spring.read2.timeBetweenEvictionRunsMillis=60000# 配置一个连接在池中最小生存的时间，单位是毫秒spring.read2.minEvictableIdleTimeMillis=300000spring.read2.validationQuery=SELECT 1 FROM DUALspring.read2.testWhileIdle=truespring.read2.testOnBorrow=falsespring.read2.testOnReturn=false# 打开PSCache，并且指定每个连接上PSCache的大小spring.read2.poolPreparedStatements=truespring.read2.maxPoolPreparedStatementPerConnectionSize=20 # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙spring.datasource.filters=stat,wall,logback# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.datasource.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000# 合并多个DruidDataSource的监控数据spring.datasource.useGlobalDataSourceStat=true # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙spring.slave.filters=stat,wall,logback# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.slave.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000# 合并多个DruidDataSource的监控数据spring.slave.useGlobalDataSourceStat=true # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙spring.read2.filters=stat,wall,logback# 通过connectProperties属性来打开mergeSql功能；慢SQL记录spring.read2.connectionProperties=druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000# 合并多个DruidDataSource的监控数据spring.read2.useGlobalDataSourceStat=true

